{"cells":[{"cell_type":"markdown","source":["## Overview\n\nThis notebook contains a Spark pipeline for processing JSON formatted data and export CSV files during the various steps of its adaptation, in order to match the target data."],"metadata":{}},{"cell_type":"code","source":["input_dir = '/FileStore/tables/'\noutdir = '/dbfs/FileStore/'\n\nfile_location = input_dir + \"supplier_car.json\"\ndf = spark.read.json(file_location)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["import pandas as pd\nimport os\n#Transposing values of columns Attr. Names and Attr. Values from rows into columns\n#Step 1, same granularity\ndfPandas = df.toPandas()\npivotedDF = dfPandas.pivot(index='ID', columns='Attribute Names', values='Attribute Values')\ndel dfPandas['Attribute Names'], dfPandas['Attribute Values']\ndfPandas = dfPandas.join(on='ID', other=pivotedDF)\n\ndfPandas = dfPandas.rename(columns={'ID': '_id'})\n\noutname = 'pre-processed.csv'\ndfPandas.to_csv(outdir+outname, index=False, encoding=\"utf-8\")\n\n#Step 2 / Normalization\n#Normalizer function\ndef normalize(df: pd.DataFrame, col: str, allowedValues: list, replaceMap: dict):\n  df[col].replace(replaceMap, inplace=True)\n  df.loc[~df[col].isin(allowedValues), col] = 'Other'\n\n#colorsMap = {\"anthrazit\": \"Anthracite\", \"anthrazit mét.\": \"Metallic Anthracite\", \"blau\": \"Blue\", \"blau mét.\": \"Metallic Blue\", \"silber\": \"Silver\", \"silber mét.\": \"Metallic Silver\", \"violett\": \"Purple\", \"violett mét.\": \"Metallic Purple\", \"weiss\": \"White\", \"weiss mét.\": \"Metallic White\", \"bordeaux\": \"Maroon\", \"bordeaux mét.\": \"Metallic Maroon\", \"braun\": \"Brown\", \"braun mét.\": \"Metallic Brown\", \"gelb\": \"Yellow\", \"gelb mét.\": \"Metallic Yellow\", \"gold\": \"Gold\", \"gold mét.\": \"Metallic Gold\", \"grau\": \"Grey\", \"grau mét.\": \"Metallic Grey\", \"grün\": \"Green\", \"grün mét.\": \"Metallic Green\", \"beige\": \"Beige\", \"beige mét.\": \"Metallic Beige\", \"orange\": \"Orange\", \"orange mét.\": \"Metallic Orange\", \"rot\": \"Red\", \"red mét.\": \"Metallic Red\", \"schwarz\": \"Black\", \"schwarz mét.\": \"Metallic Black\"}\n\n#Bordeaux taken out as it is not in the target list, metallic colors taken out as not present in target data\ncolorsMap = {\"anthrazit\": \"Anthracite\", \"anthrazit mét.\": \"Anthracite\", \"blau\": \"Blue\", \"blau mét.\": \"Blue\", \"silber\": \"Silver\", \"silber mét.\": \"Silver\", \"violett\": \"Purple\", \"violett mét.\": \"Purple\", \"weiss\": \"White\", \"weiss mét.\": \"White\", \"braun\": \"Brown\", \"braun mét.\": \"Brown\", \"gelb\": \"Yellow\", \"gelb mét.\": \"Yellow\", \"gold\": \"Gold\", \"gold mét.\": \"Gold\", \"grau\": \"Grey\", \"grau mét.\": \"Grey\", \"grün\": \"Green\", \"grün mét.\": \"Green\", \"beige\": \"Beige\", \"beige mét.\": \"Beige\", \"orange\": \"Orange\", \"orange mét.\": \"Orange\", \"rot\": \"Red\", \"red mét.\": \"Red\", \"schwarz\": \"Black\", \"schwarz mét.\": \"Black\"}\n\n#Normalization of body colors\nlistOfAllowedColors = list(colorsMap.values())\nnormalize(dfPandas, 'BodyColorText', listOfAllowedColors, colorsMap)\n\n#============================TESTING===============================\ntestDF = dfPandas\ncolor = testDF['BodyColorText'][2]\ntestDF['BodyColorText'][2] = 'NoColor' \nnormalize(testDF, 'BodyColorText', listOfAllowedColors, colorsMap)\n#Positive assertion\nassert(testDF['BodyColorText'][2] == 'Other'), 'It didn\\'t work!'\n#Negative assertion\nassert('NoColor' not in testDF.loc[:, 'BodyColorText']), 'It did not work!'\n#=================================================================\n\n#Normalization of internal colors\nnormalize(dfPandas, 'InteriorColorText', listOfAllowedColors, colorsMap)\n\n#Normalization of MakeText\ndfPandas['MakeText'] = dfPandas['MakeText'].str.title()\n\n#Normalization of ModelText\n#This is already like the model attribute in target data\n\n#Normalization of TypeName and ModelText into target data's model_variant: model_variant = TypeName - ModelText ==================> this will be called only during the integration phase as it will erase the TypeName attribute\ndef normalizeTypeName(df: pd.DataFrame):\n  df['model_variant'] = df['TypeName']\n  for index, value in df['TypeName'].items():\n    #ML 350 Inspiration - ML 350 => Inspiration ; Phaeton 6.0 W12 4Motion\t- PHAETON => 6.0 W12 4Motion\n    if (str(value) != str(df['ModelText'][index])): #Otherwise model_variant would become \"\" in certain cases\n      df['model_variant'][index] = value.replace(str(df['ModelText'][index]).title(), '') \\\n                                        .replace(str(df['ModelText'][index]), '')\n  del df['TypeName']\n\n#Normalization of ModelTypeText - no need, is already like target data's model\n\n#Normalization BodyTypeText (target data's carType)\n#['Cabriolet' 'SUV / Geländewagen' 'Kombi' 'Limousine' 'Coupé', 'Kompaktvan / Minivan' 'Pick-up' 'Kleinwagen' 'Sattelschlepper', 'Wohnkabine' nan]\n#Many values are not present in the target data, but I felt right to add them (as opposite to missing colors, which I considered less important for users)\n#print(dfPandas.BodyTypeText.unique())\ncarTypesMap = {\"Cabriolet\": \"Convertible / Roadster\", \"SUV / Geländewagen\": \"SUV\", \"Kombi\": \"Station Wagon\", \"Limousine\": \"Limousine\", \"Kompaktvan / Minivan\": \"Compact Van\", \"Pick-up\": \"Pick-up\", \"Kleinwagen\": \"Subcompact\", \"Sattelschlepper\": \"Trailer Truck\", \"Wohnkabine\": \"Camper shell / Truck camper\"}\n\nlistOfAllowedCarTypes = list(carTypesMap.values())\n\n#for all carTypes/rows in the BodyTypeText column, if it is not in the list of allowed car types, BodyTypeText=Other\nnormalize(dfPandas, 'BodyTypeText', listOfAllowedCarTypes, carTypesMap)\n\n#============================TESTING===============================\ncarType = testDF['BodyTypeText'][1]\ntestDF['BodyTypeText'][2] = 'Mofa' \nnormalize(testDF, 'BodyTypeText', listOfAllowedCarTypes, carTypesMap)\n#Positive assertion\nassert(testDF['BodyTypeText'][2] == 'Other'), 'It didn\\'t work!'\n#Negative assertion\nassert('Mofa' not in testDF.loc[:, 'BodyTypeText']), 'It did not work!'\n#=================================================================\n\n#Normalization DriveTypeText\n#print(dfPandas.DriveTypeText.unique()) => ['Hinterradantrieb' (Rear-wheel drive), 'Allrad' (All-wheel drive), 'Vorderradantrieb' (Front-wheel drive), 'null']\ndriveTypesMap = {\"Hinterradantrieb\": \"Rear-wheel drive\", \"Allrad\": \"All-wheel drive\", \"Vorderradantrieb\": \"Front-wheel drive\"}\nlistOfAllowedDriveTypes = list(driveTypesMap.values())\nnormalize(dfPandas, 'DriveTypeText', listOfAllowedDriveTypes, driveTypesMap)\n\n#============================TESTING===============================\ndriveType = testDF['DriveTypeText'][2]\ntestDF['DriveTypeText'][2] = '4x4' \nnormalize(testDF, 'DriveTypeText', listOfAllowedDriveTypes, driveTypesMap)\n#Positive assertion\nassert(testDF['DriveTypeText'][2] == 'Other'), 'It didn\\'t work!'\n#Negative assertion\nassert('Mofa' not in testDF.loc[:, 'DriveTypeText']), 'It did not work!'\ndel testDF\n#=================================================================\n  \n#Normalization Properties\n#up to 4 out of possibleProps, combined by a comma\npropertiesDict = {'Ab MFK': \"freshly serviced\", 'Direkt-/Parallelimport': \"direct-/parallel import\", 'Tuning': \"tuned\", 'Rennwagen': \"racing car\"}\npossibleProps = ['Ab MFK', 'Direkt-/Parallelimport', 'Tuning', 'Rennwagen']\nnormalizedProperties = dfPandas['Properties']\nnormalizedProperties = normalizedProperties.str.replace('\"', '').str.strip(' ').str.split(',') #strip=> not removing in the middle [\"Ab MFK\\\"\",\" \\\"Tuning\"]\n\ndef normalizeProperties(props) -> list:\n    newList = []\n    for prop in props:\n        prop = prop.strip(' ')\n        if prop in possibleProps:\n            newList.append(prop.replace(prop, propertiesDict[prop]))\n    return newList if len(newList) > 0 else ['Other']\n\nfor index, value in normalizedProperties.items():\n      normalizedProperties.iloc[index] = normalizeProperties(value)\n      normalizedProperties.iloc[index] = ', '.join(map(str, normalizedProperties.iloc[index])) \ndfPandas['Properties'] = normalizedProperties\n\n#Normalization of ConditionTypeText\n#Vorführmodell: Demo car, Occasion: Used, Oldtimer: Antique car / Restored, Neu: New\nconditionTypesMap = {\"Vorführmodell\": \"Demo car\", \"Occasion\": \"Used\", \"Oldtimer\": \"Antique Car / Restored\", \"Neu\": \"New\"}\nlistOfAllowedConditionTypes = list(conditionTypesMap.values())\nnormalize(dfPandas, 'ConditionTypeText', listOfAllowedConditionTypes, conditionTypesMap)\n\n#Normalization TransmissionTypeText \ntransmissionTypesMap = {\"Automatisiertes Schaltgetriebe\": \"Automated manual transmission\", \"Automatik-Getriebe\": \"Automatic\", \"Automat\": \"Automatic\", \"Schaltgetriebe manuell\": \"Manual\", \"Schaltgetriebe\": \"Manual\", \"Automat sequentiell\": \"CVT\", \"Automat stufenlos, sequentiell\": \"CVT\", \"Automat stufenlos\": \"CVT\"}\nlistOfAllowedTransmissionTypes = list(transmissionTypesMap.values())\nnormalize(dfPandas, 'TransmissionTypeText', listOfAllowedTransmissionTypes, transmissionTypesMap)\n\n#Normalization FuelTypeText\n#print(dfPandas['FuelTypeText'].unique()) ['Benzin' 'null' 'Diesel' 'Bioethanol' 'Benzin/Elektro']\nfuelTypesMap = {\"Benzin\": \"Petrol\", \"Diesel\": \"Diesel\", \"Bioethanol\": \"Bioethanol\", \"Benzin/Elektro\": \"Petrol/Electric (Hybrid)\", \"Diesel/Elektro\": \"Diesel/Electric (Hybrid)\"}\nlistOfAllowedFuelTypes = list(fuelTypesMap.values())\nnormalize(dfPandas, 'FuelTypeText', listOfAllowedFuelTypes, fuelTypesMap)\n\n#Normalization of Ccm and City into city\n#Aggregating Ccm and City into one field and deleting them, called in step 4\ndef normalizeCity(df: pd.DataFrame):\n  df['city'] = df[['Ccm', 'City']].agg(' '.join, axis=1)\n  df['zip'] = df['Ccm']\n  del df['Ccm'], df['City']\n\n#output normalized.csv\noutname = 'normalized.csv'\ndfPandas.to_csv(outdir+outname, index=False, encoding=\"utf-8\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["#Step3, Extraction\nfrom geopy.geocoders import Nominatim\n#print(dfPandas['entity_id'].unique().size) 21906, this can be a better ID\ndfPandas['_id'] = dfPandas['entity_id']\n\n#Mandatory ones\n#Separate value from unit of consumption 14.9 l/100km => 14.9, l/100km\ndfPandas['ConsumptionTotalText'] = dfPandas['ConsumptionTotalText'].str.split(' ')\ndfPandas[['extracted-value-ConsumptionTotalText', 'extracted-unit-ConsumptionTotalText']] = pd.DataFrame(dfPandas.ConsumptionTotalText.values.tolist(), index= dfPandas.index)\n\n#Building country attribute with country's code \ngeolocator = Nominatim(user_agent=\"extractCountry\")\n#extract location out of city name\ndfPandas.assign(country=\"\")\ndfPandas.assign(countryFull=\"\")\ndictCountries = {}\ndictCountriesFull = {}\n#counter = 0\nfor index, city in dfPandas['City'].items():\n    if city not in dictCountries:\n        location = geolocator.geocode(city,  addressdetails=True)\n        locationDict= location.raw['address']\n        countryCode = locationDict['country_code']\n        countryFull = locationDict['country']\n        dfPandas.loc[dfPandas.index[index], 'country'] = countryCode.upper()\n        dictCountries[city] = countryCode.upper()\n        dfPandas.loc[dfPandas.index[index], 'countryFull'] = countryFull\n        dictCountriesFull[city] = countryFull\n    else:\n        dfPandas.loc[dfPandas.index[index], 'country'] = dictCountries[city]\n        dfPandas.loc[dfPandas.index[index], 'countryFull'] = dictCountriesFull[city]\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["#KM => mileage, mileage_unit=km\ndfPandas['mileage_unit'] = 'kilometer'\n#Set up drive attribute by country code!\n#city->country->RHD/LHD\nfile_location = input_dir + \"countriesLHD.csv\"\ncountriesDF = spark.read.format('csv').load(file_location) \ncountries = countriesDF.toPandas()#pd.read_csv('dbfs??/FileStore/tables/countriesLHD.csv')\ncountries = countries.drop([0])\ndfPandas.assign(drive=\"\")\n#for each country, code, if code in the list of LHD countries, drive=LHD, else drive=RHD\nfor index, country in dfPandas['countryFull'].items():\n    if country in countries.iloc[0]: dfPandas.loc[dfPandas.index[index], 'drive'] = 'LHD' \n    else: dfPandas.loc[dfPandas.index[index], 'drive'] = 'RHD'\n#======================TESTING=============================\nrhd = dfPandas['drive'][dfPandas['drive']=='RHD'].count()\nlhd = dfPandas['drive'][dfPandas['drive']=='LHD'].count()\nassert(rhd+lhd==dfPandas.shape[0]), 'Something went wrong!'\n#==========================================================\noutname = 'extracted.csv'\ndfPandas.to_csv(outdir+outname, index=False, encoding=\"utf-8\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["newDF = dfPandas.copy()#checkpoint to not run all cells again\n#Step 4, Integration\n#this normalizes TypeName, substitutes it for model_variant and deletes TypeName\nnormalizeTypeName(newDF)\n\n#This merges Ccm and City into city, there are already some entries in city attribute of target data\n# with postal code, so I felt like joining postal code to City was the best thing to do\nnormalizeCity(newDF)\n\n#erase\ndel newDF['_id'], newDF['ModelTypeText'], newDF['TypeNameFull'], newDF['entity_id'], \\\n    newDF['ConsumptionTotalText'], newDF['countryFull'], \\\n    newDF['extracted-value-ConsumptionTotalText'], newDF['TransmissionTypeText'], \\\n    newDF['Seats'], newDF['Properties'], newDF['InteriorColorText'], newDF['Hp'], \\\n    newDF['FuelTypeText'], newDF['DriveTypeText'], newDF['Doors'], \\\n    newDF['ConsumptionRatingText'], newDF['Co2EmissionText']\n#Renaming columns\nnewDF = newDF.rename(columns={\"BodyColorText\": \"color\", \"MakeText\": \"make\", \"BodyTypeText\": \"carType\", \\\n                                    \"ConditionTypeText\": \"condition\", \"ModelText\": \"model\", \\\n                                    \"ConsumptionRatingTest\": \"Energy_label\", \"FuelTypeText\": \"fuel_type\", \\\n                                    \"extracted-unit-ConsumptionTotalText\": \"fuel_consumption_unit\", \\\n                                    \"InteriorColorText\": \"interior_color\", \"FirstRegMonth\": \"manufacture_month\", \\\n                                    \"FirstRegYear\": \"manufacture_year\", \"Co2EmissionText\": \"CO_2_emissions\", \\\n                                    \"Km\": \"mileage\"})\nnewDF[\"currency\"] = 'null'\nnewDF[\"type\"] = 'null'\nnewDF[\"price_on_request\"] = 'null'\n#Rearranging columns\ncols = ['carType', 'color', 'condition', 'currency', 'drive', 'city', 'country', 'make', 'manufacture_year', 'mileage', 'mileage_unit', 'model', 'model_variant', 'price_on_request', 'type', 'zip', 'manufacture_month', 'fuel_consumption_unit']\nnewDF = newDF[cols]\n#print(newDF['country'].unique())\noutname = 'integrated.csv'\nnewDF.to_csv(outdir+outname, index=False, encoding=\"utf-8\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6}],"metadata":{"name":"2020-02-18 - DBFS Example","notebookId":527000572453850},"nbformat":4,"nbformat_minor":0}
